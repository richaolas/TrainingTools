{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test\n",
    "\n",
    "1. 两点间距离公式：\n",
    "\n",
    "$$|AB|=\\sqrt{(x_1-x_2)^2 + (y_1-y_2)^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"15\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img, ImageDataGenerator, array_to_img\n",
    "from tensorflow.python.saved_model import tag_constants\n",
    "from tensorflow.python.compiler.tensorrt import trt_convert as trt\n",
    "from tensorflow.keras.applications import MobileNetV2 \n",
    "\n",
    "\n",
    "import glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import time \n",
    "import datetime\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from bokeh.io import output_notebook, show, push_notebook\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.layouts import row\n",
    "from bokeh.core.validation import silence\n",
    "from bokeh.core.validation.warnings import MISSING_RENDERERS\n",
    "silence(MISSING_RENDERERS, True)\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "import matplotlib.ticker as ticker \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Resize the dataset to native resolutions of the network and overwrite the original \n",
    "# dataset \n",
    "#\n",
    "def resize_dataset_and_overwrite(img_size, root, dataset):\n",
    "    \n",
    "    img_cols = img_size[0]\n",
    "    img_rows = img_size[1]\n",
    "    \n",
    "    img_files = glob.glob(root+'/'+dataset+'/*/*.jpg')\n",
    "\n",
    "    # Convert all images for Mobilenet format (224, 224)\n",
    "    for fn in tqdm(img_files):\n",
    "\n",
    "        image = cv2.imread(fn)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        image = cv2.resize(image, (img_cols, img_rows), interpolation=cv2.INTER_CUBIC)\n",
    "        \n",
    "        cv2.imwrite(fn, cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "#\n",
    "# Example path '/data/aiqs-datasets/rim-dataset/training'\n",
    "#\n",
    "def augment_dataset_with_distortions(root, dataset):\n",
    "    \n",
    "    print(\"Augmenting dataset with distorted variants [\",root+'/'+dataset,\"]\")\n",
    "\n",
    "    # Augment training\n",
    "    img_files = glob.glob(root+'/'+dataset+'/*/*.jpg')\n",
    "\n",
    "    # Define ranges of the image distortion to include in the generator\n",
    "    datagen = ImageDataGenerator(\n",
    "            rotation_range=20,\n",
    "            width_shift_range=0.1,\n",
    "            height_shift_range=0.1,\n",
    "            shear_range=0.1,\n",
    "            zoom_range=0.1,\n",
    "            horizontal_flip=False,\n",
    "            fill_mode='nearest')\n",
    "\n",
    "    for fn in tqdm(img_files):\n",
    "        filename = fn.split('/')[-1]\n",
    "        img = load_img(fn)  \n",
    "        x = img_to_array(img)  \n",
    "        x = x.reshape((1,) + x.shape)  \n",
    "\n",
    "        # the .flow() command below generates batches of randomly transformed images\n",
    "        # and saves the results to the same directory as the original image\n",
    "        destdir = fn[:-len(filename)]\n",
    "\n",
    "        n_aug = 3\n",
    "        i = 0\n",
    "        for batch in datagen.flow(x, batch_size=1, \n",
    "                                  save_to_dir=destdir, \n",
    "                                  save_prefix='aug_', \n",
    "                                  save_format='jpg'):\n",
    "            i += 1\n",
    "            if i > n_aug:\n",
    "                break \n",
    "\n",
    "#\n",
    "# Read dataset and labels \n",
    "#\n",
    "def read_dataset_and_labels(root, dataset, target_size):\n",
    "    \n",
    "    print(\"Reading dataset from [\"+root+'/'+dataset+\"] as \", dataset)\n",
    "    print(\" - Image shape to be used (w,h,c) = \", target_size)\n",
    "    \n",
    "    dataset_files = glob.glob(root+'/'+dataset+'/*/*.jpg')\n",
    "    num_classes = len(glob.glob(root+'/'+dataset+'/*'))\n",
    "    \n",
    "    print(\" - Number of classes\", num_classes)\n",
    "    print(\" - Number of images\", len(dataset_files))\n",
    "    \n",
    "    w,h,c = target_size # width, height, channels \n",
    "    \n",
    "    n_images = len(dataset_files)\n",
    "    imgs = np.ndarray((n_images, w, h, c))\n",
    "    labels = np.ndarray((n_images))\n",
    "\n",
    "    idx = 0\n",
    "    for fn in tqdm(dataset_files):\n",
    "        \n",
    "        # class\n",
    "        cat = fn.split('/')[-2]\n",
    "\n",
    "        img = load_img(fn, grayscale=False, target_size=(w, h))\n",
    "        img = img_to_array(img)\n",
    "        \n",
    "        imgs[idx] = img/255 # rescale to [0,1] range\n",
    "        labels[idx] = int(cat)\n",
    "\n",
    "        idx = idx + 1\n",
    "        \n",
    "    # Convert images to single precision and convert categorical labels to \n",
    "    # vectors: 0 to [1, 0, 0, ...], 1 to [0, 1, 0, ...] etc.\n",
    "        \n",
    "    # Convert images to float\n",
    "    imgs = imgs.astype('float32')\n",
    "    \n",
    "    # Convert labels to categorical\n",
    "    labels = tf.keras.utils.to_categorical(labels, num_classes)\n",
    "        \n",
    "    return imgs, labels\n",
    "\n",
    "#\n",
    "# Monitoring of the training process with plots updated every epoch showing \n",
    "# history of the optimization proccess i.e. loss and accuracy for both training and testing \n",
    "# datasets. \n",
    "# \n",
    "class TrainingPlot(tf.keras.callbacks.Callback):\n",
    "\n",
    "    # This function is called when the training begins\n",
    "    def on_train_begin(self, logs={}):\n",
    "        \n",
    "        self.losses = []\n",
    "        self.acc = []\n",
    "        self.val_losses = []\n",
    "        self.val_acc = []\n",
    "        self.logs = []\n",
    "        \n",
    "        output_notebook()\n",
    "        self.p1 = figure(plot_width=450, plot_height=300, title='Losses')\n",
    "        self.p2 = figure(plot_width=450, plot_height=300, title='Accuracy')\n",
    "\n",
    "        self.target = show(row(self.p1, self.p2), notebook_handle=True)\n",
    "                \n",
    "    # This function is called at the end of each epoch\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "\n",
    "        # Append the logs, losses and accuracies to the lists\n",
    "        self.logs.append(logs)\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.acc.append(logs.get('accuracy'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "        self.val_acc.append(logs.get('val_accuracy'))\n",
    "\n",
    "        # Before plotting ensure at least 2 epochs have passed\n",
    "        if len(self.losses) > 0:\n",
    "\n",
    "            N = np.arange(0, len(self.losses))\n",
    "            \n",
    "            self.p1.line(N, self.losses, color='blue', legend_label='Training')\n",
    "            self.p1.line(N, self.val_losses, color='red', legend_label='Testing')\n",
    "            \n",
    "            self.p2.line(N, self.acc, color='blue', legend_label='Training')\n",
    "            self.p2.line(N, self.val_acc, color='red', legend_label='Testing')\n",
    "            \n",
    "            self.p1.legend.location = \"top_left\"\n",
    "            self.p2.legend.location = \"top_left\"\n",
    "\n",
    "            push_notebook(handle=self.target)\n",
    "\n",
    "# \n",
    "# Evaluate model's accuracy\n",
    "#\n",
    "def evaluate_model(model, test_img, y_test):\n",
    "    \n",
    "    score = model.evaluate(test_img, y_test, verbose=0)\n",
    "    \n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "    \n",
    "#\n",
    "# Plot random sample of image for spot checking \n",
    "#\n",
    "def plot_random_sample(n, x, y):\n",
    "    \n",
    "    n_elements = len(x)\n",
    "    \n",
    "    n_col = 5 \n",
    "    n_row = n // n_col \n",
    "    if n % n_col > 0:\n",
    "        n_row += 1\n",
    "    \n",
    "    f = plt.figure(figsize=(12,6))\n",
    "    \n",
    "    subplot_idx=1\n",
    "    for i in range(0,n):\n",
    "        \n",
    "        idx = random.randint(0,n_elements-1)\n",
    "        label_str = str(np.argmax(y[idx]))\n",
    "        f.add_subplot(n_row, n_col, subplot_idx, title=label_str)\n",
    "        plt.imshow(x[idx])\n",
    "        subplot_idx += 1\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show() \n",
    "    \n",
    "#\n",
    "# Function to equalize the histogram of colored image\n",
    "#\n",
    "def equalize_colored_histogram(img):\n",
    "    \n",
    "    # Change colorspace to YUV\n",
    "    img_yuv = cv2.cvtColor(img, cv2.COLOR_BGR2YUV)\n",
    "    \n",
    "    # equalize the histogram of the Y channel\n",
    "    img_yuv[:,:,0] = cv2.equalizeHist(img_yuv[:,:,0])\n",
    "\n",
    "    # convert the YUV image back to RGB format\n",
    "    img_output = cv2.cvtColor(img_yuv, cv2.COLOR_YUV2BGR)\n",
    "    \n",
    "    return img_output\n",
    "\n",
    "#\n",
    "# Change of the gamma value of the image \n",
    "#\n",
    "def adjust_gamma(image, gamma=1.0):\n",
    "    # build a lookup table mapping the pixel values [0, 255] to\n",
    "    # their adjusted gamma values\n",
    "    invGamma = 1.0 / gamma\n",
    "    table = np.array([((i / 255.0) ** invGamma) * 255\n",
    "        for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    "\n",
    "    # apply gamma correction using the lookup table\n",
    "    return cv2.LUT(image, table)\n",
    "\n",
    "#\n",
    "# Generate uniformly gamma augmented set\n",
    "# \n",
    "def dataset_augment_with_gamma_variations(path):\n",
    "    \n",
    "    dirs = glob.glob(path+'/*')\n",
    "    \n",
    "    for dir_name in sorted(dirs):\n",
    "        \n",
    "        print('augmenting gamma -- working in - ',dir_name.split('/')[-1])\n",
    "    \n",
    "        fns = glob.glob(dir_name+'/*')\n",
    "\n",
    "        # Loop over files\n",
    "        for fn in tqdm(fns):\n",
    "\n",
    "            # read image\n",
    "            img = cv2.imread(fn)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            # equalize histogram\n",
    "            img_eq = equalize_colored_histogram(img)\n",
    "\n",
    "            # Loop over gamma changes\n",
    "            for new_gamma in [0.25, 0.5, 0.75, 1.0, 1.125, 1.25, 1.5]:\n",
    "\n",
    "                img_gamma = adjust_gamma(img_eq, gamma=new_gamma)\n",
    "\n",
    "                new_fn = dir_name + '/' + fn.split('/')[-1][:-4] + '-gamma-' + str(new_gamma) + '.jpg'\n",
    "                cv2.imwrite(new_fn, cv2.cvtColor(img_gamma, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "batch_size = 64\n",
    "epochs = 100\n",
    "num_classes = 17\n",
    "\n",
    "dataset_root = '/data/datasets/2020-02-20-rim-dataset--training'\n",
    "resize_and_overwrite_original_files = False\n",
    "augment_with_distortions = False\n",
    "augment_with_gamma = True\n",
    "target_size = (224,224,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MobileNet-V2\n",
    "from tensorflow.keras.applications import MobileNetV2 \n",
    "model = MobileNetV2(input_shape=target_size, \n",
    "                    weights=None, \n",
    "                    classes=num_classes)\n",
    "\n",
    "solver = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=solver,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if resize_and_overwrite_original_files:\n",
    "    print('-- Resizing and overwriting -- ')\n",
    "    resize_dataset_and_overwrite(target_size, dataset_root, 'training')\n",
    "    resize_dataset_and_overwrite(target_size, dataset_root, 'testing')\n",
    "    \n",
    "if augment_with_gamma:\n",
    "    print('-- Augmenting with gamma changes --')\n",
    "    dataset_augment_with_gamma_variations(dataset_root+'/training')\n",
    "    #dataset_augment_with_gamma_variations(dataset_root+'/testing')\n",
    "    \n",
    "if augment_with_distortions:\n",
    "    print('-- Augmenting with distortions --')\n",
    "    augment_dataset_with_distortions(dataset_root, 'training')\n",
    "    #augment_dataset_with_distortions(dataset_root, 'testing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('-- Reading datasets --')\n",
    "train_img, y_train = read_dataset_and_labels(dataset_root, 'training', target_size)\n",
    "test_img, y_test = read_dataset_and_labels(dataset_root, 'testing', target_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spot-check dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "print('-- Training set --')\n",
    "plot_random_sample(n, train_img, y_train)\n",
    "\n",
    "print('-- Testing set --')\n",
    "plot_random_sample(n, test_img, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "log_dir=\"logs/rim/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "print('-- Training -- ')\n",
    "plot_losses = TrainingPlot()\n",
    "history = model.fit(train_img, \n",
    "                    y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(test_img, y_test), \n",
    "                    shuffle=True, \n",
    "                    callbacks=[plot_losses, tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('-- Model evaluation --')\n",
    "evaluate_model(model, test_img, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "filename = 'mobilenetv2_model'\n",
    "model.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.predict(test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Test accuracy for each class separately\n",
    "files_to_plot = 5\n",
    "size = 224\n",
    "test_classes_dir = '/data/datasets/2020-02-20-rim-dataset--training/testing/*'\n",
    "\n",
    "classes_dirs = sorted(glob.glob(test_classes_dir))\n",
    "\n",
    "print('List of directories to test:')\n",
    "for i in classes_dirs:\n",
    "    print(i)\n",
    "\n",
    "all_results = {}\n",
    "\n",
    "for dir_name in classes_dirs:\n",
    "    \n",
    "    print('')\n",
    "    print('Testing in : ', dir_name)\n",
    "    print('')\n",
    "    test_files = glob.glob(dir_name+'/*.jpg')\n",
    "    n_test_images = len(test_files)\n",
    "    test_img = np.ndarray((n_test_images, size, size, 3))\n",
    "    test_labels = np.ndarray((n_test_images))\n",
    "\n",
    "    idx = 0\n",
    "    for fn in test_files:\n",
    "        cat = fn.split('/')[-2]\n",
    "\n",
    "        img = load_img(fn, grayscale=False, target_size=(size, size))\n",
    "        img = img_to_array(img)\n",
    "        test_img[idx] = img/255 # rescale to [0,1] range\n",
    "        test_labels[idx] = int(cat)\n",
    "\n",
    "        idx = idx + 1\n",
    "\n",
    "    \n",
    "\n",
    "    test_img = test_img.astype('float32')\n",
    "    print('test_img shape:', test_img.shape)\n",
    "\n",
    "    y_test_binary = tf.keras.utils.to_categorical(test_labels, num_classes)\n",
    "\n",
    "    # Run model\n",
    "    result = model.predict(test_img)\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    wrong_files = []\n",
    "\n",
    "    for i in range(0,len(result)):\n",
    "        predicted_id = np.argmax(result[i])\n",
    "        predicted_id_prob = result[i][predicted_id]\n",
    "        ground_truth_id = np.argmax(y_test_binary[i])\n",
    "\n",
    "        # Check if the predicted label matches ground truth\n",
    "        status = predicted_id == ground_truth_id\n",
    "        \n",
    "        # Keep names of files where we made mistakes\n",
    "        if status == 0:\n",
    "            wrong_files.append(test_files[i])\n",
    "\n",
    "        correct += status\n",
    "        total += 1\n",
    "\n",
    "        #fn = test_files[i].split('/')[-2:]\n",
    "        \n",
    "    print('Correct samples :', correct)\n",
    "    print('Total samples :', total)\n",
    "    print('Accuracy : ', (correct/total).round(2))\n",
    "    print('Files with errors:', wrong_files)\n",
    "    \n",
    "    print('Sample images:')\n",
    "    plot_random_sample(files_to_plot, test_img, y_test_binary)\n",
    "    \n",
    "    print('Wrong images:')\n",
    "    for fn in wrong_files:\n",
    "        print(fn)\n",
    "        img = load_img(fn, grayscale=False, target_size=(size, size))\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "        \n",
    "    \n",
    "    class_index = dir_name.split('/')[-1]\n",
    "    \n",
    "    all_results[class_index] = (correct/total).round(2)\n",
    "    \n",
    "# Print and plot results of all tests\n",
    "print(all_results)    \n",
    "\n",
    "names = list(all_results.keys())\n",
    "values = list(all_results.values())\n",
    "\n",
    "plt.bar(range(len(all_results)),values,tick_label=names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
